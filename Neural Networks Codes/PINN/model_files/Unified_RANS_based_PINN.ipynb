{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97f1967",
   "metadata": {},
   "source": [
    "# Neural Network using PINN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e44c41",
   "metadata": {},
   "source": [
    "The idea of this neural network is to take the following inputs:\n",
    "   - dU/dy : Derivative of U in wall-normal direction\n",
    "   - k : Turbulent kinetic energy, k = 0.5*(u'u' + v'v' + w'w') \n",
    "   - y^+ : Grid point in wall-normal direction\n",
    "   - Re : Reynold value\n",
    "\n",
    "and provide us the Reynolds Stress tensor components below:\n",
    "   - u'u' : Variance of u\n",
    "   - v'v' : Variance of v\n",
    "   - w'w' : Variance of w\n",
    "   - u'v' : Covariance of u and v \n",
    "   - u'w' : Covariance of u and w \n",
    "   - v'w' : Covariance of v and w\n",
    "\n",
    "$$\n",
    "\\text{NN}\\begin{bmatrix}\n",
    "\\frac{dU}{dy} \\\\\n",
    "k \\\\\n",
    "y^+ \\\\\n",
    "Re\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "u'u' \\\\\n",
    "v'v' \\\\\n",
    "w'w' \\\\\n",
    "u'v' \\\\\n",
    "u'w' \\\\\n",
    "v'w'\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Additionnaly, the architecture that has been chosen for the model is the Residual Network !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bb4baa",
   "metadata": {},
   "source": [
    "## Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b023887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, num_input, num_output, num_hidden, num_layers):\n",
    "        super(NN, self).__init__()\n",
    "        activation = nn.Tanh()\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(num_input, num_hidden),\n",
    "            activation\n",
    "        )\n",
    "\n",
    "        # Define hidden layers\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.hidden_layers.append(nn.Sequential(\n",
    "                nn.Linear(num_hidden, num_hidden),\n",
    "                activation\n",
    "            ))\n",
    "\n",
    "        self.output_layer = nn.Linear(num_hidden, num_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        for i, hidden_layer in enumerate(self.hidden_layers):\n",
    "            if i % 2 == 0:  # Add residual connection every 2 layers\n",
    "                x = x + hidden_layer(x)\n",
    "            else:\n",
    "                x = hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cff20e",
   "metadata": {},
   "source": [
    "## Defining the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eb2e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self, dns_rst, Lx, nu, y, add_dns_data):\n",
    "        super(Loss, self).__init__()\n",
    "        self.dns_rst = dns_rst\n",
    "        self.y = y\n",
    "        self.Lx = Lx\n",
    "        self.nu = nu\n",
    "        self.add_dns_data = add_dns_data\n",
    "\n",
    "    def forward(self, predicted_reynolds_stress):\n",
    "        # Extracting DNS data\n",
    "        uu = self.dns_rst[:,0]\n",
    "        vv = self.dns_rst[:,1]\n",
    "        ww = self.dns_rst[:,2]\n",
    "        uw = self.dns_rst[:,3]\n",
    "        uv = self.dns_rst[:,4]\n",
    "        vw = self.dns_rst[:,5]\n",
    "        \n",
    "        density = 1\n",
    "        dns_reynolds_stress = torch.stack([uu, vv, ww, uw, uv, vw], dim=1)\n",
    "        \n",
    "        dP_dx, d2U_d2y, d_uv_dy, dP_dy, d_vv_dy = compute_derivatives(self.Lx, self.y, predicted_reynolds_stress, self.add_dns_data)\n",
    "\n",
    "        momentum_x_loss = torch.mean(torch.square((-((1/density) * dP_dx) + self.nu * d2U_d2y) - d_uv_dy))\n",
    "        momentum_y_loss = torch.mean(torch.square(-((1/density) * torch.tensor(dP_dy)) - torch.tensor(d_vv_dy)))\n",
    "        loss = torch.mean((predicted_reynolds_stress - dns_reynolds_stress)**2)\n",
    "        \n",
    "        total_loss = loss + momentum_x_loss + momentum_y_loss\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "\n",
    "def compute_derivatives(Lx, y, predicted_stresses, add_dns_data):\n",
    "    # x-direction\n",
    "    dP_dx = add_dns_data[:, 1] / Lx\n",
    "    dU_dy = np.gradient(add_dns_data[:, 0], y, edge_order=2)\n",
    "    d2U_d2y = np.gradient(dU_dy, y, edge_order=2)\n",
    "    d_uv_dy = np.gradient(predicted_stresses[:, 4].detach().numpy(), y, edge_order=2)  \n",
    "\n",
    "    # y-direction\n",
    "    dP_dy = np.gradient(add_dns_data[:, 1], y, edge_order=2)\n",
    "    d_vv_dy = np.gradient(predicted_stresses[:, 1].detach().numpy(), y, edge_order=2)\n",
    "\n",
    "    return dP_dx, torch.tensor(d2U_d2y), torch.tensor(d_uv_dy), dP_dy, d_vv_dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb6973f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input array: (2811, 8)\n",
      "Shape of the output array: (2811, 6)\n",
      "Shape of the input tensor: (2811, 8)\n",
      "Shape of the output tensor: (2811, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_paths = [r\"C:\\Users\\Sohai\\OneDrive - Cranfield University\\GroupProject\\Neural-Network\\DNS_data\\Channel_data\\mirrored_LM_Channel_0180_prof.csv\",\n",
    "              r\"C:\\Users\\Sohai\\OneDrive - Cranfield University\\GroupProject\\Neural-Network\\DNS_data\\Channel_data\\mirrored_LM_Channel_2000_prof.csv\", \n",
    "              r\"C:\\Users\\Sohai\\OneDrive - Cranfield University\\GroupProject\\Neural-Network\\DNS_data\\Channel_data\\mirrored_LM_Channel_5200_prof.csv\",\n",
    "              r\"C:\\Users\\Sohai\\OneDrive - Cranfield University\\GroupProject\\Neural-Network\\DNS_data\\Couette_data\\mirrored_LM_Couette_R0093_100PI_prof.csv\",\n",
    "              r\"C:\\Users\\Sohai\\OneDrive - Cranfield University\\GroupProject\\Neural-Network\\DNS_data\\Couette_data\\mirrored_LM_Couette_R0220_020PI_prof.csv\",]\n",
    "\n",
    "# Reynolds numbers\n",
    "Re = [180, 2000, 5200, 93, 220]\n",
    "U_tau = [6.37309e-02, 4.58794e-02, 4.14872e-02, 6.19417e-02, 5.47883e-02]\n",
    "Lx = [8 * np.pi] * 3 + [100 * np.pi, 20 * np.pi]\n",
    "nu = [3.50000e-04, 2.30000e-05, 8.00000e-06, 6.66667e-04, 2.50000e-04]\n",
    "\n",
    "#Initialize the input list\n",
    "input_features = []\n",
    "\n",
    "# Initialize empty lists to store stress tensor components\n",
    "uu_list = []\n",
    "vv_list = []\n",
    "ww_list = []\n",
    "uw_list = []\n",
    "uv_list = []\n",
    "vw_list = []\n",
    "\n",
    "u_list = []\n",
    "k_list = []\n",
    "\n",
    "# Loop through each file\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    data = pd.read_csv(file_path)\n",
    "    mean_velocity_grad = data['dU/dy'].values\n",
    "    k = data['k'].values\n",
    "    y_plus = data['y^+'].values\n",
    "    U = data['U'].values\n",
    "    P = data['P'].values\n",
    "\n",
    "    # Combine all the input features needed for the model to use  \n",
    "    features = np.column_stack((mean_velocity_grad, k, y_plus, np.full_like(mean_velocity_grad, Re[i]), U, P, np.full_like(mean_velocity_grad, Lx[i]), np.full_like(mean_velocity_grad, nu[i]))) \n",
    "    input_features.append(features)\n",
    "\n",
    "X = np.concatenate(input_features, axis=0)\n",
    "\n",
    "print(\"Shape of the input array:\", X.shape)\n",
    "\n",
    "for file_path in file_paths:\n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    # Extract the stress tensor columns and convert them to NumPy arrays\n",
    "    uu = data[\"u'u'\"].values\n",
    "    vv = data[\"v'v'\"].values\n",
    "    ww = data[\"w'w'\"].values\n",
    "    uw = data[\"u'w'\"].values\n",
    "    uv = data[\"u'v'\"].values\n",
    "    vw = data[\"v'w'\"].values\n",
    "    \n",
    "    uu_list.append(uu)\n",
    "    vv_list.append(vv)\n",
    "    ww_list.append(ww)\n",
    "    uw_list.append(uw)\n",
    "    uv_list.append(uv)\n",
    "    vw_list.append(vw)\n",
    "\n",
    "# Concatenate the stress tensor components along axis 0 to create the output labels\n",
    "uu = np.concatenate(uu_list, axis=0)\n",
    "vv = np.concatenate(vv_list, axis=0)\n",
    "ww = np.concatenate(ww_list, axis=0)\n",
    "uw = np.concatenate(uw_list, axis=0)\n",
    "uv = np.concatenate(uv_list, axis=0)\n",
    "vw = np.concatenate(vw_list, axis=0)\n",
    "\n",
    "# Combine Reynolds stress tensor components\n",
    "y = np.column_stack((uu, vv, ww, uw, uv, vw))\n",
    "\n",
    "print(\"Shape of the output array:\", y.shape)\n",
    "\n",
    "# Convert the numpey array into tensor\n",
    "X_train_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "print(\"Shape of the input tensor:\", X.shape)\n",
    "print(\"Shape of the output tensor:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0603e2",
   "metadata": {},
   "source": [
    "## Train Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c333e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2000], Loss: 3.10461\n",
      "Epoch [101/2000], Loss: 0.52168\n",
      "Epoch [201/2000], Loss: 0.33038\n",
      "Epoch [301/2000], Loss: 0.27632\n",
      "Epoch [401/2000], Loss: 0.17400\n",
      "Epoch [501/2000], Loss: 0.13316\n",
      "Epoch [601/2000], Loss: 0.11456\n",
      "Epoch [701/2000], Loss: 0.15779\n",
      "Epoch [801/2000], Loss: 0.10227\n",
      "Epoch [901/2000], Loss: 0.09678\n",
      "Epoch [1001/2000], Loss: 0.09478\n",
      "Epoch [1101/2000], Loss: 0.09329\n",
      "Epoch [1201/2000], Loss: 0.09081\n",
      "Epoch [1301/2000], Loss: 0.08576\n",
      "Epoch [1401/2000], Loss: 0.08831\n",
      "Epoch [1501/2000], Loss: 0.08481\n",
      "Epoch [1601/2000], Loss: 0.08032\n",
      "Epoch [1701/2000], Loss: 0.07857\n",
      "Epoch [1801/2000], Loss: 0.07731\n",
      "Epoch [1901/2000], Loss: 0.07678\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "# Initialization of the model main parameters\n",
    "num_input = 4  # Number of input features\n",
    "num_output = 6  #  Number of output features (for the 6 components of the Reynolds stress tensor)\n",
    "num_hidden = 30  # Number of neurones\n",
    "num_layers = 8 # Number of hidden layers\n",
    "\n",
    "model = NN(num_input, num_output, num_hidden, num_layers)\n",
    "\n",
    "# Defining the loss function \n",
    "loss_fn = Loss(y_train_tensor, X_train_tensor[:, -2], X_train_tensor[:, -1], X_train_tensor[:,2], X_train_tensor[:, 4:6])\n",
    "\n",
    "# Defining the optimizer\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=0.0025, weight_decay=0.001) \n",
    "\n",
    "# Initialize an empty list to store the loss values\n",
    "loss_values = []\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()  # Reset gradients\n",
    "    \n",
    "    predicted_reynolds_stress = model(X_train_tensor[:, :4])  \n",
    "    \n",
    "    # Add regularization term to the loss\n",
    "    l2_regularization_loss = 0\n",
    "    for param in model.parameters():\n",
    "        l2_regularization_loss += torch.norm(param, p=2)  # L2 norm regularization\n",
    "        \n",
    "    loss = loss_fn(predicted_reynolds_stress)  # Compute loss\n",
    "    \n",
    "    lambda_reg = 0.0025\n",
    "    loss += lambda_reg * l2_regularization_loss\n",
    "    \n",
    "    loss.backward()  # Backward pass\n",
    "    \n",
    "    optimizer.step()  # Update model parameters\n",
    "    \n",
    "    # Append the current loss to the list\n",
    "    loss_values.append(loss.item())\n",
    "    \n",
    "    if (epoch) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.5f}')\n",
    "\n",
    "print('Training finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1175ebfd",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "799f73d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(model.state_dict(), 'model_Unified_RANS_based_PINN.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0366b6f5",
   "metadata": {},
   "source": [
    "## Test Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "609baadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (511, 4)\n",
      "Shape of y: (511, 6)\n"
     ]
    }
   ],
   "source": [
    "# file_path = r\"C:\\Users\\Sohai\\OneDrive - Cranfield University\\GroupProject\\Neural-Network\\DNS_data\\Couette_data\\mirrored_LM_Couette_R0500_020PI_prof.csv\"\n",
    "file_path = r\"C:\\Users\\Sohai\\OneDrive - Cranfield University\\GroupProject\\Neural-Network\\DNS_data\\Channel_data\\mirrored_LM_Channel_1000_prof.csv\"\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "# Extract the 'U' column and convert it to a NumPy array\n",
    "mean_velocity_grad_test = data['dU/dy'].values\n",
    "k_test = data['k'].values\n",
    "y_plus_test = data['y^+'].values\n",
    "Re_test = 1000\n",
    "\n",
    "# Combine all the input features needed for the model to use \n",
    "features_test = np.column_stack((mean_velocity_grad_test, k_test, y_plus_test, np.full_like(mean_velocity_grad_test, Re_test)))\n",
    "\n",
    "# Append the input features to the list\n",
    "L_test = []\n",
    "L_test.append(features_test)\n",
    "X_test_ = np.concatenate(L_test, axis=0) \n",
    "\n",
    "print(\"Shape of X:\", X_test_.shape)\n",
    "\n",
    "# Initialize empty lists to store stress tensor components\n",
    "uu_list = []\n",
    "vv_list = []\n",
    "ww_list = []\n",
    "uw_list = []\n",
    "uv_list = []\n",
    "vw_list = []\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "uu = data[\"u'u'\"].values\n",
    "vv = data[\"v'v'\"].values\n",
    "ww = data[\"w'w'\"].values\n",
    "uw = data[\"u'w'\"].values\n",
    "uv = data[\"u'v'\"].values\n",
    "vw = data[\"v'w'\"].values\n",
    "\n",
    "uu_list.append(uu)\n",
    "vv_list.append(vv)\n",
    "ww_list.append(ww)\n",
    "uw_list.append(uw)\n",
    "uv_list.append(uv)\n",
    "vw_list.append(vw)\n",
    "\n",
    "# Concatenate the stress tensor components along axis 0 to create the output columns\n",
    "uu = np.concatenate(uu_list, axis=0)\n",
    "vv = np.concatenate(vv_list, axis=0)\n",
    "ww = np.concatenate(ww_list, axis=0)\n",
    "uw = np.concatenate(uw_list, axis=0)\n",
    "uv = np.concatenate(uv_list, axis=0)\n",
    "vw = np.concatenate(vw_list, axis=0)\n",
    "\n",
    "\n",
    "# Combine Reynolds stress tensor components\n",
    "y_features_test = np.column_stack((uu, vv, ww, uw, uv, vw))\n",
    "\n",
    "M = []\n",
    "M.append(y_features_test)\n",
    "y_test = np.concatenate(M, axis=0) \n",
    "print(\"Shape of y:\", y_test.shape)\n",
    "\n",
    "# Convert the numpey array into tensor\n",
    "X_test_tensor = torch.tensor(X_test_, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d513c4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Data: 0.027166243642568588\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_reynolds_stress = model(X_test_tensor[:, :4])\n",
    "\n",
    "mse = nn.MSELoss()\n",
    "test_loss = mse(predicted_reynolds_stress, y_test_tensor)\n",
    "\n",
    "print(\"Mean Squared Error on Test Data:\", test_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a240c4",
   "metadata": {},
   "source": [
    "# Calculate the Kinematic viscosity k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a2c8861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the columns of variances and calculate the kinematic viscosity:\n",
    "selected_columns = predicted_reynolds_stress[:, [0, 1, 2]]\n",
    "column_sum = torch.sum(selected_columns, dim=1)\n",
    "k = 0.5 * column_sum\n",
    "\n",
    "# Concatenate the column k with all the others\n",
    "predicted_reynolds_stress_with_k = torch.cat((predicted_reynolds_stress, k.unsqueeze(1)), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9350ab96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([511, 7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_reynolds_stress_with_k.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2527e529",
   "metadata": {},
   "source": [
    "# Save the predicted outcome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a75138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_array = predicted_reynolds_stress_with_k.numpy()\n",
    "\n",
    "file_name = file_path.split('\\\\')[-1]\n",
    "file_path = r\"C:\\Users\\Sohai\\OneDrive - Cranfield University\\GroupProject\\Neural-Network\\Result_comparison\\\\\" + \"Result_Unified_RANS_\" + file_name\n",
    "\n",
    "# Header for the csv file\n",
    "header = \"u'u',v'v',w'w',u'w',u'v',v'w',k\"\n",
    "\n",
    "# Save the NumPy array to a CSV file with the header\n",
    "np.savetxt(file_path, tensor_array, delimiter=',', header=header, comments='')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
