{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97f1967",
   "metadata": {},
   "source": [
    "# Neural Network using PINN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e44c41",
   "metadata": {},
   "source": [
    "The idea of this neural network is to take the following inputs:\n",
    "   - dU/dy : Derivative of U in wall-normal direction\n",
    "   - k : Turbulent kinetic energy, k = 0.5*(u'u' + v'v' + w'w') \n",
    "   - y^+ : Grid point in wall-normal direction\n",
    "   - Re : Reynold value\n",
    "\n",
    "and provide us the Reynolds Stress tensor components below:\n",
    "   - u'u' : Variance of u\n",
    "   - v'v' : Variance of v\n",
    "   - w'w' : Variance of w\n",
    "   - u'v' : Covariance of u and v \n",
    "   - u'w' : Covariance of u and w \n",
    "   - v'w' : Covariance of v and w\n",
    "\n",
    "$$\n",
    "\\text{NN}\\begin{bmatrix}\n",
    "\\frac{dU}{dy} \\\\\n",
    "k \\\\\n",
    "y^+ \\\\\n",
    "Re\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "u'u' \\\\\n",
    "v'v' \\\\\n",
    "w'w' \\\\\n",
    "u'v' \\\\\n",
    "u'w' \\\\\n",
    "v'w'\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Additionnaly, the architecture that has been chosen for the model is the Residual Network !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bb4baa",
   "metadata": {},
   "source": [
    "## Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b023887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, num_input, num_output, num_hidden, num_layers):\n",
    "        super(NN, self).__init__()\n",
    "        activation = nn.Tanh()\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(num_input, num_hidden),\n",
    "            activation\n",
    "        )\n",
    "\n",
    "        # Define hidden layers\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.hidden_layers.append(nn.Sequential(\n",
    "                nn.Linear(num_hidden, num_hidden),\n",
    "                activation\n",
    "            ))\n",
    "\n",
    "        self.output_layer = nn.Linear(num_hidden, num_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        for i, hidden_layer in enumerate(self.hidden_layers):\n",
    "            if i % 2 == 0:  # Add residual connection every 2 layers\n",
    "                x = x + hidden_layer(x)\n",
    "            else:\n",
    "                x = hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cff20e",
   "metadata": {},
   "source": [
    "## Defining the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eb2e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self, dns_rst, y, add_dns_data):\n",
    "        super(Loss, self).__init__()\n",
    "        self.dns_rst = dns_rst\n",
    "        self.y = y\n",
    "        self.add_dns_data = add_dns_data\n",
    "        self.wall_distance = 8\n",
    "\n",
    "    def forward(self, predicted_reynolds_stress):\n",
    "        # Extracting DNS data\n",
    "        uu = self.dns_rst[:,0]\n",
    "        vv = self.dns_rst[:,1]\n",
    "        ww = self.dns_rst[:,2]\n",
    "        uw = self.dns_rst[:,3]\n",
    "        uv = self.dns_rst[:,4]\n",
    "        vw = self.dns_rst[:,5]\n",
    "        \n",
    "        density = 1\n",
    "        lambda_1 = 0.01\n",
    "        lambda_2 = 0.001\n",
    "        \n",
    "        dns_reynolds_stress = torch.stack([uu, vv, ww, uw, uv, vw], dim=1)\n",
    "        \n",
    "        # Apply boundary conditions to the predicted Reynolds stress tensor\n",
    "#         predicted_reynolds_stress[0:3, :] = 0  # Set the first values of each column to zeros\n",
    "        \n",
    "        dP_dx, d2U_d2y, d_uv_dy, dP_dy, d_vv_dy = compute_derivatives(self.y, predicted_reynolds_stress, self.add_dns_data)\n",
    "\n",
    "        pysindy_loss = torch.mean((- d2U_d2y + 1.057*d_uv_dy -272.974*(dP_dx**2)*d_uv_dy - 1779.846*(dP_dx**3)*d_uv_dy + 178958.541*(dP_dx**3)*(d_uv_dy**2))**2)\n",
    "\n",
    "        momentum_y_loss = torch.mean(torch.square(-((1/density) * torch.tensor(dP_dy)) - torch.tensor(d_vv_dy)))\n",
    "        \n",
    "        loss = torch.mean((predicted_reynolds_stress - dns_reynolds_stress)**2)\n",
    "        \n",
    "        # Compute boundary condition penalties\n",
    "\n",
    "        # Loss penalizing deviation from the boundary condition near the wall\n",
    "        uv_boundary_loss = torch.mean(torch.square(predicted_reynolds_stress[:, 1][:self.wall_distance]))  # Near the lower wall\n",
    "        uv_boundary_loss += torch.mean(torch.square(predicted_reynolds_stress[:, 1][-self.wall_distance:]))  # Near the upper wall\n",
    "\n",
    "        total_loss = loss + pysindy_loss + momentum_y_loss + uv_boundary_loss \n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "\n",
    "def compute_derivatives(y, predicted_stresses, add_dns_data):\n",
    "    # x-direction\n",
    "    dP_dx = add_dns_data[:, 0]\n",
    "    d2U_d2y = add_dns_data[:, 2]\n",
    "    d_uv_dy = np.gradient(predicted_stresses[:, 4].detach().numpy(), y, edge_order=2)  \n",
    "\n",
    "    # y-direction\n",
    "    dP_dy = add_dns_data[:, 1]\n",
    "    d_vv_dy = np.gradient(predicted_stresses[:, 1].detach().numpy(), y, edge_order=2)\n",
    "\n",
    "    return dP_dx, torch.tensor(d2U_d2y), torch.tensor(d_uv_dy), dP_dy, d_vv_dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb6973f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input array: (130000, 9)\n",
      "Shape of the output array: (130000, 6)\n",
      "Shape of the input tensor: (130000, 9)\n",
      "Shape of the output tensor: (130000, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_paths = [r\"C:\\Users\\Sohai\\OneDrive - Cranfield University\\GroupProject\\Neural-Network\\DNS_data\\PySindy_data\\Channel_mirrored_data\\mirrored_LM_Channel_0180_prof.csv\",\n",
    "              r\"C:\\Users\\Sohai\\OneDrive - Cranfield University\\GroupProject\\Neural-Network\\DNS_data\\PySindy_data\\Channel_mirrored_data\\mirrored_LM_Channel_0550_prof.csv\",\n",
    "              r\"C:\\Users\\Sohai\\OneDrive - Cranfield University\\GroupProject\\Neural-Network\\DNS_data\\PySindy_data\\Channel_mirrored_data\\mirrored_LM_Channel_2000_prof.csv\", \n",
    "              r\"C:\\Users\\Sohai\\OneDrive - Cranfield University\\GroupProject\\Neural-Network\\DNS_data\\PySindy_data\\Channel_mirrored_data\\mirrored_LM_Channel_5200_prof.csv\"]\n",
    "\n",
    "\n",
    "# Reynolds numbers\n",
    "Re = [180, 550, 2000,5200]\n",
    "Lx = [8 * np.pi] * 4\n",
    "nu = [3.50000e-04, 1.00000e-04, 2.30000e-05, 8.00000e-06]\n",
    "\n",
    "#Initialize the input list\n",
    "input_features = []\n",
    "\n",
    "# Initialize empty lists to store stress tensor components\n",
    "uu_list = []\n",
    "vv_list = []\n",
    "ww_list = []\n",
    "uw_list = []\n",
    "uv_list = []\n",
    "vw_list = []\n",
    "\n",
    "u_list = []\n",
    "k_list = []\n",
    "\n",
    "# Loop through each file\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    data = pd.read_csv(file_path)\n",
    "    mean_velocity_grad = data['dU/dy'].values\n",
    "    k = data['DNS_k'].values\n",
    "    y_plus = data['y^+'].values\n",
    "    mean_velocity_grad2 = data['d2U_dy2'].values\n",
    "    dP_dx = data['dP_dx'].values\n",
    "    dP_dy = data['dP_dy'].values\n",
    "\n",
    "    # Combine all the input features needed for the model to use ---      \n",
    "    features = np.column_stack((mean_velocity_grad, k, y_plus, np.full_like(mean_velocity_grad, Re[i]), dP_dx, dP_dy, mean_velocity_grad2, np.full_like(mean_velocity_grad, Lx[i]), np.full_like(mean_velocity_grad, nu[i])))\n",
    "    input_features.append(features)\n",
    "\n",
    "X = np.concatenate(input_features, axis=0)\n",
    "\n",
    "print(\"Shape of the input array:\", X.shape)\n",
    "\n",
    "for file_path in file_paths:\n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    # Extract the stress tensor columns and convert them to NumPy arrays\n",
    "    uu = data[\"u'u'\"].values\n",
    "    vv = data[\"v'v'\"].values\n",
    "    ww = data[\"w'w'\"].values\n",
    "    uw = data[\"u'w'\"].values\n",
    "    uv = data[\"u'v'\"].values\n",
    "    vw = data[\"v'w'\"].values\n",
    "    \n",
    "    uu_list.append(uu)\n",
    "    vv_list.append(vv)\n",
    "    ww_list.append(ww)\n",
    "    uw_list.append(uw)\n",
    "    uv_list.append(uv)\n",
    "    vw_list.append(vw)\n",
    "\n",
    "# Concatenate the stress tensor components along axis 0 to create the output labels\n",
    "uu = np.concatenate(uu_list, axis=0)\n",
    "vv = np.concatenate(vv_list, axis=0)\n",
    "ww = np.concatenate(ww_list, axis=0)\n",
    "uw = np.concatenate(uw_list, axis=0)\n",
    "uv = np.concatenate(uv_list, axis=0)\n",
    "vw = np.concatenate(vw_list, axis=0)\n",
    "\n",
    "# Combine Reynolds stress tensor components\n",
    "y = np.column_stack((uu, vv, ww, uw, uv, vw))\n",
    "\n",
    "print(\"Shape of the output array:\", y.shape)\n",
    "\n",
    "# Convert the numpey array into tensor\n",
    "X_train_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "print(\"Shape of the input tensor:\", X.shape)\n",
    "print(\"Shape of the output tensor:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0603e2",
   "metadata": {},
   "source": [
    "## Train Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c333e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sohai\\AppData\\Local\\Temp\\ipykernel_2996\\3118642292.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return dP_dx, torch.tensor(d2U_d2y), torch.tensor(d_uv_dy), dP_dy, d_vv_dy\n",
      "C:\\Users\\Sohai\\AppData\\Local\\Temp\\ipykernel_2996\\3118642292.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  momentum_y_loss = torch.mean(torch.square(-((1/density) * torch.tensor(dP_dy)) - torch.tensor(d_vv_dy)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2500], Loss: 1.89966\n",
      "Epoch [101/2500], Loss: 0.41223\n",
      "Epoch [201/2500], Loss: 0.21849\n",
      "Epoch [301/2500], Loss: 0.19828\n",
      "Epoch [401/2500], Loss: 0.19338\n",
      "Epoch [501/2500], Loss: 0.18999\n",
      "Epoch [601/2500], Loss: 0.18429\n",
      "Epoch [701/2500], Loss: 0.17551\n",
      "Epoch [801/2500], Loss: 0.16755\n",
      "Epoch [901/2500], Loss: 0.16153\n",
      "Epoch [1001/2500], Loss: 0.15590\n",
      "Epoch [1101/2500], Loss: 0.15098\n",
      "Epoch [1201/2500], Loss: 0.14457\n",
      "Epoch [1301/2500], Loss: 0.13839\n",
      "Epoch [1401/2500], Loss: 0.13568\n",
      "Epoch [1501/2500], Loss: 0.13265\n",
      "Epoch [1601/2500], Loss: 0.13022\n",
      "Epoch [1701/2500], Loss: 0.12945\n",
      "Epoch [1801/2500], Loss: 0.12770\n",
      "Epoch [1901/2500], Loss: 0.12729\n",
      "Epoch [2001/2500], Loss: 0.12690\n",
      "Epoch [2101/2500], Loss: 0.12561\n",
      "Epoch [2201/2500], Loss: 0.12579\n",
      "Epoch [2301/2500], Loss: 0.12338\n",
      "Epoch [2401/2500], Loss: 0.12361\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "# Initialization of the model\n",
    "num_input = 4  # Number of input features\n",
    "num_output = 6  #  Number of output features (for the 6 components of the Reynolds stress tensor)\n",
    "num_hidden = 64  # Number of neurones\n",
    "num_layers = 10 # Number of hidden layers\n",
    "\n",
    "model = NN(num_input, num_output, num_hidden, num_layers)\n",
    "\n",
    "# Defining the loss function\n",
    "loss_fn = Loss(y_train_tensor, X_train_tensor[:, 2], X_train_tensor[:, 4:7])\n",
    "\n",
    "# Defining the optimizer\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=0.00025, weight_decay=0.00001) \n",
    "\n",
    "# Initialize an empty list to store the loss values\n",
    "loss_values = []\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2500\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()  # Reset gradients\n",
    "    \n",
    "    predicted_reynolds_stress = model(X_train_tensor[:, :4])  \n",
    "    \n",
    "    # Add regularization term to the loss\n",
    "    l2_regularization_loss = 0\n",
    "    for param in model.parameters():\n",
    "        l2_regularization_loss += torch.norm(param, p=2)  # L2 norm regularization\n",
    "        \n",
    "    loss = loss_fn(predicted_reynolds_stress)  # Compute loss\n",
    "    \n",
    "    lambda_reg = 0.0025\n",
    "    loss += lambda_reg * l2_regularization_loss\n",
    "    \n",
    "    loss.backward()  # Backward pass\n",
    "    \n",
    "    optimizer.step()  # Update model parameters\n",
    "    \n",
    "    # Append the current loss to the list\n",
    "    loss_values.append(loss.item())\n",
    "    \n",
    "    if (epoch) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.5f}')\n",
    "    \n",
    "print('Training finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4061d502",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c56378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(model.state_dict(), 'model_PySindy_based_PINN_channel.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0366b6f5",
   "metadata": {},
   "source": [
    "## Test Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "609baadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (40000, 4)\n",
      "Shape of y: (40000, 6)\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\Sohai\\OneDrive - Cranfield University\\GroupProject\\Neural-Network\\DNS_data\\PySindy_data\\Channel_mirrored_data\\mirrored_LM_Channel_1000_prof.csv\"\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "# Extract the 'U' column and convert it to a NumPy array\n",
    "mean_velocity_grad_test = data['dU/dy'].values\n",
    "k_test = data['DNS_k'].values\n",
    "y_plus_test = data['y^+'].values\n",
    "Re_test = 1000\n",
    "\n",
    "# Combine all the input features needed for the model to use --- mean_velocity_grad_test    , np.full_like(U_test, 500)\n",
    "features_test = np.column_stack((mean_velocity_grad_test, k_test, y_plus_test, np.full_like(mean_velocity_grad_test, Re_test)))\n",
    "\n",
    "# Append the input features to the list\n",
    "L_test = []\n",
    "L_test.append(features_test)\n",
    "X_test_ = np.concatenate(L_test, axis=0) \n",
    "\n",
    "print(\"Shape of X:\", X_test_.shape)\n",
    "\n",
    "# Initialize empty lists to store stress tensor components\n",
    "uu_list = []\n",
    "vv_list = []\n",
    "ww_list = []\n",
    "uw_list = []\n",
    "uv_list = []\n",
    "vw_list = []\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "uu = data[\"u'u'\"].values\n",
    "vv = data[\"v'v'\"].values\n",
    "ww = data[\"w'w'\"].values\n",
    "uw = data[\"u'w'\"].values\n",
    "uv = data[\"u'v'\"].values\n",
    "vw = data[\"v'w'\"].values\n",
    "\n",
    "uu_list.append(uu)\n",
    "vv_list.append(vv)\n",
    "ww_list.append(ww)\n",
    "uw_list.append(uw)\n",
    "uv_list.append(uv)\n",
    "vw_list.append(vw)\n",
    "\n",
    "# Concatenate the stress tensor components along axis 0 to create the output columns\n",
    "uu = np.concatenate(uu_list, axis=0)\n",
    "vv = np.concatenate(vv_list, axis=0)\n",
    "ww = np.concatenate(ww_list, axis=0)\n",
    "uw = np.concatenate(uw_list, axis=0)\n",
    "uv = np.concatenate(uv_list, axis=0)\n",
    "vw = np.concatenate(vw_list, axis=0)\n",
    "\n",
    "# Combine Reynolds stress tensor components\n",
    "y_features_test = np.column_stack((uu, vv, ww, uw, uv, vw))\n",
    "\n",
    "M = []\n",
    "M.append(y_features_test)\n",
    "y_test = np.concatenate(M, axis=0) \n",
    "print(\"Shape of y:\", y_test.shape)\n",
    "\n",
    "# Convert the numpey array into tensor\n",
    "X_test_tensor = torch.tensor(X_test_, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a240c4",
   "metadata": {},
   "source": [
    "# Calculate the Kinematic viscosity k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a2c8861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the columns of variances and calculate the kinematic viscosity:\n",
    "selected_columns = predicted_reynolds_stress[:, [0, 1, 2]]\n",
    "column_sum = torch.sum(selected_columns, dim=1)\n",
    "k = 0.5 * column_sum\n",
    "\n",
    "# Concatenate the column k with all the others\n",
    "predicted_reynolds_stress_with_k = torch.cat((predicted_reynolds_stress, k.unsqueeze(1)), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9350ab96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40000, 7])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_reynolds_stress_with_k.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cfb7d5",
   "metadata": {},
   "source": [
    "# Save the predicted outcome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a75138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_array = predicted_reynolds_stress_with_k.numpy()\n",
    "\n",
    "file_name = file_path.split('\\\\')[-1]\n",
    "file_path = r\"C:\\Users\\Sohai\\OneDrive - Cranfield University\\GroupProject\\Neural-Network\\Result_comparison\\\\\" + \"Result_PySindy_\" + file_name\n",
    "\n",
    "# Header for the csv file\n",
    "header = \"u'u',v'v',w'w',u'w',u'v',v'w',k\"\n",
    "\n",
    "# Save the NumPy array to a CSV file with the header\n",
    "np.savetxt(file_path, tensor_array, delimiter=',', header=header, comments='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd398e29",
   "metadata": {},
   "source": [
    "# Loading the model\n",
    "\n",
    "Load the model and test it with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a92d39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (input_layer): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0-8): 9 x Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=64, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialization of the model\n",
    "num_input = 4  # Number of input features\n",
    "num_output = 6  #  Number of output features (for the 6 components of the Reynolds stress tensor)\n",
    "num_hidden = 64  # Number of neurones\n",
    "num_layers = 10 # Number of hidden layers\n",
    "\n",
    "model_test = NN(num_input, num_output, num_hidden, num_layers)\n",
    "model_test.load_state_dict(torch.load('model_PySindy_based_PINN_Channel.pth'))\n",
    "model_test.eval()  # Make sure to set the model to evaluation mode after loading\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_reynolds_stress = model_test(Input_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
